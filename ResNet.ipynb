{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import urandom\n",
    "from  keras. callbacks  import  ModelCheckpoint, LearningRateScheduler\n",
    "from  keras. models  import  Model\n",
    "from  keras. layers  import  Dense, Conv1D, Conv2D,Input, ReLU,Reshape, Permute, Add, Flatten, BatchNormalization, Activation, Dropout,DepthwiseConv2D\n",
    "from keras.regularizers import l2\n",
    "import  matplotlib. pyplot  as  plt\n",
    "import time\n",
    "from  keras  import  layers\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "bs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sbox = np.array([0xc, 0x5, 0x6, 0xb, 0x9, 0x0, 0xa, 0xd, 0x3, 0xe, 0xf, 0x8, 0x4, 0x7, 0x1, 0x2])\n",
    "\n",
    "raw_P = [0,  16, 32, 48, 1,  17, 33, 49, 2,  18, 34, 50, 3,  19, 35, 51,\n",
    "     4,  20, 36, 52, 5,  21, 37, 53, 6,  22, 38, 54, 7,  23, 39, 55,\n",
    "     8,  24, 40, 56, 9,  25, 41, 57, 10, 26, 42, 58, 11, 27, 43, 59,\n",
    "     12, 28, 44, 60, 13, 29, 45, 61, 14, 30, 46, 62, 15, 31, 47, 63]\n",
    "raw_P = np.array(raw_P)\n",
    "\n",
    "# Big-Edian\n",
    "index = np.array([63 - i for i in range(64)])\n",
    "raw_P = 63 - raw_P[index]\n",
    "\n",
    "P = np.array([np.where(raw_P == i) for i in range(64)])\n",
    "P = np.squeeze(P)\n",
    "\n",
    "# for decryption, to be test\n",
    "Sbox_inverse = np.array([0x5, 0xe, 0xf, 0x8, 0xc, 0x1, 0x2, 0xd, 0xb, 0x4, 0x6, 0x3, 0x0, 0x7, 0x9, 0xa])\n",
    "P_inverse = raw_P\n",
    "\n",
    "# for updating keys\n",
    "KP = np.array([(i+61) % 80 for i in range(80)])\n",
    "\n",
    "\n",
    "# x shape: (-1, 4)\n",
    "def get_Sbox_output_enc(x):\n",
    "    n, m = np.shape(x)\n",
    "    assert m == 4\n",
    "    x_val = x[:, 0] * 8 + x[:, 1] * 4 + x[:, 2] * 2 + x[:, 3]\n",
    "    y_val = Sbox[x_val]\n",
    "    output = np.zeros((n, 4), dtype=np.uint8)\n",
    "    for i in range(4):\n",
    "        output[:, i] = (y_val >> (3 - i)) & 1\n",
    "    # print('y_val shape is ', np.shape(y_val))\n",
    "    return output\n",
    "\n",
    "\n",
    "# x shape: (-1, 4)\n",
    "def get_Sbox_output_dec(x):\n",
    "    n, m = np.shape(x)\n",
    "    assert m == 4\n",
    "    x_val = x[:, 0] * 8 + x[:, 1] * 4 + x[:, 2] * 2 + x[:, 3]\n",
    "    y_val = Sbox_inverse[x_val]\n",
    "    output = np.zeros((n, 4), dtype=np.uint8)\n",
    "    for i in range(4):\n",
    "        output[:, i] = (y_val >> (3 - i)) & 1\n",
    "    # print('y_val shape is ', np.shape(y_val))\n",
    "    return output\n",
    "\n",
    "\n",
    "# keys shape: (-1, 80)\n",
    "def update_master_key(keys, round_counter):\n",
    "    tp = keys[:, KP]\n",
    "    new_keys = copy.deepcopy(tp)\n",
    "    new_keys[:, :4] = get_Sbox_output_enc(tp[:, :4])\n",
    "    round_counter_arr = np.array([(round_counter >> (4-i)) & 1 for i in range(5) ], dtype=np.uint8)\n",
    "    new_keys[:, 60:65] = tp[:, 60:65] ^ round_counter_arr\n",
    "    return new_keys\n",
    "\n",
    "\n",
    "# keys shape: (-1, 80)\n",
    "def expand_key(keys, nr):\n",
    "    n, m = np.shape(keys)\n",
    "    assert m == 80\n",
    "    ks = np.zeros((nr+1, n, 64), dtype=np.uint8)\n",
    "    ks[0] = keys[:, :64]\n",
    "    for i in range(1, nr+1):\n",
    "        keys = update_master_key(keys, i)\n",
    "        ks[i] = keys[:, :64]\n",
    "    return ks\n",
    "\n",
    "\n",
    "# x shape: (-1, 64)\n",
    "def sBoxLayer_enc(x):\n",
    "    n, m = np.shape(x)\n",
    "    assert m == 64\n",
    "    output = np.zeros((n, 64), dtype=np.uint8)\n",
    "    for i in range(16):\n",
    "        st = 4 * i\n",
    "        output[:, st:st+4] = get_Sbox_output_enc(x[:, st:st+4])\n",
    "    return output\n",
    "\n",
    "\n",
    "# x shape: (-1, 64)\n",
    "def sBoxLayer_dec(x):\n",
    "    n, m = np.shape(x)\n",
    "    assert m == 64\n",
    "    output = np.zeros((n, 64), dtype=np.uint8)\n",
    "    for i in range(16):\n",
    "        st = 4 * i\n",
    "        output[:, st:st+4] = get_Sbox_output_dec(x[:, st:st+4])\n",
    "    return output\n",
    "\n",
    "\n",
    "# x shape: (-1, 64)\n",
    "def pLayer_enc(x):\n",
    "    output = x[:, P]\n",
    "    return output\n",
    "\n",
    "\n",
    "# x shape: (-1, 64)\n",
    "def pLayer_dec(x):\n",
    "    output = x[:, P_inverse]\n",
    "    return output\n",
    "\n",
    "\n",
    "# x shape: (-1, 64)\n",
    "# subkeys shape: (-1, 64)\n",
    "def enc_one_round(x, subkeys):\n",
    "    y = sBoxLayer_enc(x)\n",
    "    z = pLayer_enc(y)\n",
    "    output = z ^ subkeys\n",
    "    return output\n",
    "def dec_one_round(x, subkeys):\n",
    "    y = pLayer_dec(x)\n",
    "    z = sBoxLayer_dec(y)\n",
    "    output = z ^ subkeys\n",
    "    return output\n",
    "\n",
    "\n",
    "def encrypt(x, ks):\n",
    "    nr = ks.shape[0]\n",
    "    y = x ^ ks[0]\n",
    "    for i in range(1, nr):\n",
    "        y = enc_one_round(y, ks[i])\n",
    "    return y\n",
    "def decrypt(x, ks):\n",
    "    nr = ks.shape[0]\n",
    "    y = x ^ ks[nr-1]\n",
    "    for i in range(1, nr):\n",
    "        y = dec_one_round(y, ks[nr - 1 - i])\n",
    "    return y\n",
    "def decrypt_1(x):\n",
    "    y = pLayer_dec(x)\n",
    "    z = sBoxLayer_dec(y)\n",
    "    return y,z\n",
    "def decrypt_2(x):\n",
    "    y = pLayer_dec(x)\n",
    "#     z = sBoxLayer_dec(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def make_train_data(subkeyy,n=10**7, nr=9):\n",
    "    x0 = np.frombuffer(urandom(n * 8), dtype=np.uint64)  # .reshape(-1, 1)\n",
    "    p0 = np.zeros((n, 64), dtype=np.uint8)\n",
    "    for i in range(64):\n",
    "        off = 63 - i\n",
    "        p0[:, i] = (x0 >> off) & 1\n",
    "    arr = [[0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 1, 1], [0, 1, 0, 0], [0, 1, 0, 1], [0, 1, 1, 0],\n",
    "           [0, 1, 1, 1], [1, 0, 0, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 1, 1], [1, 1, 0, 0], [1, 1, 0, 1],\n",
    "           [1, 1, 1, 0], [1, 1, 1, 1]]\n",
    "#     master_keys = np.frombuffer(urandom(n * 80), dtype=np.uint8).reshape(-1, 80) & 1\n",
    "    subkeys = expand_key(subkeyy, nr)\n",
    "    c0 = encrypt(p0, subkeys)\n",
    "\n",
    " \n",
    "\n",
    "    #生成正样本\n",
    "    pp_1=p0.copy()\n",
    "    for j in range(4):\n",
    "        pp_1[:,j+60]=pp_1[:,j+60]^arr[0][j]\n",
    "    c0_1 = encrypt(pp_1, subkeys)\n",
    "    c0_1_xor=np.bitwise_xor(c0,c0_1)\n",
    "\n",
    "    c0_0_2,c0_0=decrypt_1(np.bitwise_xor(c0,c0))\n",
    "    c0_1_xor_2,c0_1_xor_tran=decrypt_1(c0_1_xor)\n",
    "    creal=np.concatenate((c0_0,c0_1_xor_tran),axis=1)\n",
    "    creal_1=np.concatenate((c0_0_2,c0_1_xor_2),axis=1)\n",
    "#     creal=np.concatenate((c0_0,np.bitwise_xor(c0_0,c0_1_xor)),axis=1) #解密一轮在异或\n",
    "#     creal_1=np.concatenate((c0_1,np.bitwise_xor(c0,c0_1)),axis=1)\n",
    "    # creal_0=np.concatenate((c0,c0_1),axis=1) #解密一轮直接做\n",
    "    for i in range(1,14,2):\n",
    "        pp=p0.copy()\n",
    "        pp_1=p0.copy()\n",
    "        for j in range(4):\n",
    "            pp[:,j+60]=pp[:,j+60]^arr[i][j]\n",
    "            pp_1[:,j+60]=pp_1[:,j+60]^arr[i+1][j]\n",
    "        c1=encrypt(pp, subkeys)\n",
    "        c1_1=encrypt(pp_1, subkeys)\n",
    "\n",
    "        c1_xor=np.bitwise_xor(c0,c1)\n",
    "        c1_1_xor=np.bitwise_xor(c0,c1_1)\n",
    "        c1_xor_tran_2,c1_xor_tran=decrypt_1(c1_xor)\n",
    "        c1_1_xor_tran_2,c1_1_xor_tran=decrypt_1(c1_1_xor)\n",
    "        \n",
    "        creal=np.concatenate((creal,c1_xor_tran,c1_1_xor_tran),axis=1)\n",
    "        creal_1=np.concatenate((creal_1,c1_xor_tran_2,c1_1_xor_tran_2),axis=1)\n",
    "\n",
    "#         creal=np.concatenate((creal,np.bitwise_xor(c0_0,c1_xor),np.bitwise_xor(c0_0,c1_1_xor)),axis=1)#解密一轮在异或\n",
    "#         creal_1=np.concatenate((creal_1,np.bitwise_xor(c0_1,c1),np.bitwise_xor(c0_1,c1_1)),axis=1)\n",
    "        # creal_0=np.concatenate((creal_0,c1,c1_1),axis=1)#解密一轮直接做\n",
    "    #生成负样本\n",
    "    x1 = np.frombuffer(urandom(n * 8), dtype=np.uint64)\n",
    "    p1 = np.zeros((n, 64), dtype=np.uint8)\n",
    "    x1_1 = np.frombuffer(urandom(n * 8), dtype=np.uint64)\n",
    "    p1_1 = np.zeros((n, 64), dtype=np.uint8)\n",
    "    for i in range(64):\n",
    "        off = 63 - i\n",
    "        p1[:, i] = (x1 >> off) & 1\n",
    "        p1_1[:, i] = (x1_1 >> off) & 1\n",
    "    c2=encrypt(p1, subkeys)\n",
    "    c2_1=encrypt(p1_1, subkeys)\n",
    "\n",
    "    c2_1_xor=np.bitwise_xor(c2,c2_1)\n",
    "\n",
    "    c2_2_2,c2_2=decrypt_1(np.bitwise_xor(c2,c2))\n",
    "    c2_1_xor_2,c2_1_xor_tran=decrypt_1(c2_1_xor)\n",
    "    crand=np.concatenate((c2_2,c2_1_xor_tran),axis=1)\n",
    "    crand_1=np.concatenate((c2_2_2,c2_1_xor_2),axis=1)\n",
    "#     crand=np.concatenate((c2_2,np.bitwise_xor(c2_2,c2_1_xor)),axis=1)  #异或值\n",
    "#     crand_1=np.concatenate((c2_1,np.bitwise_xor(c2,c2_1)),axis=1)  #异或值\n",
    "    # crand_0=np.concatenate((c2,c2_1),axis=1)\n",
    "    for j in range(7):\n",
    "        x1 = np.frombuffer(urandom(n * 8), dtype=np.uint64)\n",
    "        p1 = np.zeros((n, 64), dtype=np.uint8)\n",
    "        x1_1 = np.frombuffer(urandom(n * 8), dtype=np.uint64)\n",
    "        p1_1 = np.zeros((n, 64), dtype=np.uint8)\n",
    "        for i in range(64):\n",
    "            off = 63 - i\n",
    "            p1[:, i] = (x1 >> off) & 1\n",
    "            p1_1[:, i] = (x1_1 >> off) & 1\n",
    "        c3=encrypt(p1, subkeys)\n",
    "        c3_1=encrypt(p1_1, subkeys)\n",
    "\n",
    "        c3_xor=np.bitwise_xor(c2,c3)\n",
    "        c3_1_xor=np.bitwise_xor(c2,c3_1)\n",
    "\n",
    "        c3_xor_tran_2,c3_xor_tran=decrypt_1(c3_xor)\n",
    "        c3_1_xor_tran_2,c3_1_xor_tran=decrypt_1(c3_1_xor)\n",
    "\n",
    "        crand=np.concatenate((crand,c3_xor_tran,c3_1_xor_tran),axis=1)\n",
    "        crand_1=np.concatenate((crand_1,c3_xor_tran_2,c3_1_xor_tran_2),axis=1)\n",
    "#         crand=np.concatenate((crand,np.bitwise_xor(c2_2,c3_xor),np.bitwise_xor(c2_2,c3_1_xor)),axis=1)\n",
    "#         crand_1=np.concatenate((crand_1,np.bitwise_xor(c2_1,c3),np.bitwise_xor(c2_1,c3_1)),axis=1)\n",
    "        # crand_0=np.concatenate((crand_0,c3,c3_1),axis=1)\n",
    "    #生成负样本2\n",
    "\n",
    "\n",
    "#     X = np.concatenate((creal_0,crand_0))\n",
    "    X = np.concatenate((np.concatenate((creal,creal_1),axis=1),np.concatenate((crand,crand_1),axis=1)))\n",
    "    Yreal  =  np. ones(n)\n",
    "    Yrand  =  np. zeros(n)\n",
    "    Y  =  np. concatenate((Yreal, Yrand))\n",
    "    return X,Y\n",
    "# verify(n=10, nr=31)\n",
    "def make_train_data_mutil(nums,rounds):\n",
    "    master_keys = np.frombuffer(urandom(nums * 80), dtype=np.uint8).reshape(-1, 80) & 1\n",
    "    X,Y=make_train_data(master_keys,nums,rounds)\n",
    "#     X_1,Y_1=make_train_data(master_keys,nums,rounds)\n",
    "#     X_2,Y_2,crd_2=make_train_data(master_keys,nums,rounds)\n",
    "#     X_3,Y_3,crd_3=make_train_data(master_keys,nums,rounds)\n",
    "#     X_test=np.concatenate((X,X_1),axis=1)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_lr(num_epochs, high_lr, low_lr):\n",
    "    res = lambda i: low_lr + ((num_epochs - 1) - i % num_epochs) / (num_epochs - 1) * (high_lr - low_lr)\n",
    "    return (res)\n",
    "\n",
    "\n",
    "def make_checkpoint(datei):\n",
    "    res = ModelCheckpoint(datei, monitor='val_loss', save_best_only=True)\n",
    "    return (res)\n",
    "def make_resnet(num_words=16, multiset=16, num_filters=1024, num_outputs=1, d1=2048, d2=2048, word_size=8, ks=3, depth=5,\n",
    "                reg_param=0.0001, final_activation='sigmoid'):\n",
    "    # Input and preprocessing layers\n",
    "    inp = Input(shape=(num_words * 8 * multiset,))\n",
    "    rs = Reshape((num_words * multiset, 8))(inp)\n",
    "    perm = Permute((2, 1))(rs)\n",
    "    # add a single residual layer that will expand the data to num_filters channels\n",
    "    # this is a bit-sliced layer\n",
    "    conv0 = Conv1D(num_filters, kernel_size=1, padding='same', kernel_regularizer=l2(reg_param))(perm)\n",
    "    conv0 = BatchNormalization()(conv0)\n",
    "    conv0 = Activation('relu')(conv0)\n",
    "    # add residual blocks\n",
    "    shortcut = conv0\n",
    "    for i in range(depth):\n",
    "        conv1 = Conv1D(num_filters, kernel_size=ks, padding='same', kernel_regularizer=l2(reg_param))(shortcut)\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "        conv1 = Activation('relu')(conv1)\n",
    "        conv2 = Conv1D(num_filters, kernel_size=ks, padding='same', kernel_regularizer=l2(reg_param))(conv1)\n",
    "        conv2 = BatchNormalization()(conv2)\n",
    "        conv2 = Dropout(0.2)(conv2)\n",
    "        conv2 = Activation('relu')(conv2)\n",
    "        shortcut = Add()([shortcut, conv2])\n",
    "    # add prediction head\n",
    "    flat1 = Flatten()(shortcut)\n",
    "    dense1 = Dense(d1, kernel_regularizer=l2(reg_param))(flat1)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    dense1 = Activation('relu')(dense1)\n",
    "    dense2 = Dense(d2, kernel_regularizer=l2(reg_param))(dense1)\n",
    "    dense2 = BatchNormalization()(dense2)\n",
    "    dense2 = Activation('relu')(dense2)\n",
    "    dense2 = Dropout(0.2)(dense2)\n",
    "    out = Dense(num_outputs, activation=final_activation, kernel_regularizer=l2(reg_param))(dense2)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    return (model)\n",
    "\n",
    "\n",
    "def train_present_distinguisher(num_epochs, num_rounds, depth):\n",
    "    # create the network\n",
    "    try:\n",
    "      tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    except ValueError:\n",
    "      tpu = None\n",
    "\n",
    "    # TPUStrategy for distributed training\n",
    "    if tpu:\n",
    "      tf.config.experimental_connect_to_cluster(tpu)\n",
    "      tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "      strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "      print(\"train on tpu\")\n",
    "    else: # default strategy that works on CPU and single GPU\n",
    "      strategy = tf.distribute.get_strategy()\n",
    "    with strategy.scope():\n",
    "        net = make_resnet(depth=depth, reg_param=0.00001)\n",
    "        net.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
    "    # generate training and validation data and test data\n",
    "    print(1)\n",
    "    X,Y=make_train_data_mutil(2**20,num_rounds)\n",
    "    print(2)\n",
    "    X_eval,Y_eval=make_train_data_mutil(2**16,num_rounds)\n",
    "    print(3)\n",
    "    # X_test, Y_test = make_train_data(2 ** 8, num_rounds)\n",
    "    # create learnrate schedule\n",
    "    lr = LearningRateScheduler(cyclic_lr(10, 0.002, 0.0001))\n",
    "    # train and evaluate\n",
    "    time_start = time.time()\n",
    "    h  =  net.fit(X, Y, epochs=num_epochs, batch_size=bs, validation_data=(X_eval, Y_eval), callbacks=[lr])\n",
    "    # loss, accuracy  =  net. evaluate(X_test, Y_test)\n",
    "    time_end = time.time()\n",
    "    total_time = time_end - time_start\n",
    "    \n",
    "    print(\"\\nWhen training for a\", num_rounds, \"round PRESENT \", num_epochs, \"epochs:\")\n",
    "    print(\"\\nBest validation accuracy: \", np.max(h.history['val_acc']))\n",
    "    # print('\\nTest loss:', loss)\n",
    "    # print('\\nTest accuracy:', accuracy)\n",
    "    # f = open(save_path + \"result_for_lyu_train_PRESENT.txt\", \"a\")\n",
    "    print('\\nTotal training time is: %.2f seconds.' % total_time)\n",
    "    return (net, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_present_distinguisher(50, num_rounds=8, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,Y_test=make_train_data_mutil(2**16,8)\n",
    "loss, accuracy  =  model. evaluate(X_test, Y_test)\n",
    "print('\\nTest loss:', loss)\n",
    "print('\\nTest accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
